{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "994f90c8",
      "metadata": {
        "id": "994f90c8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3711e54",
      "metadata": {
        "id": "d3711e54"
      },
      "outputs": [],
      "source": [
        "train=pd.read_csv(r'C:\\Users\\System162L\\Downloads\\QC_WORKING\\qc_train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5635930",
      "metadata": {
        "id": "d5635930"
      },
      "outputs": [],
      "source": [
        "test=pd.read_csv(r'C:\\Users\\System162L\\Downloads\\QC_WORKING\\qc_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f498213",
      "metadata": {
        "id": "7f498213"
      },
      "outputs": [],
      "source": [
        "train_new=pd.read_csv(r'C:\\Users\\System162L\\Downloads\\QC_WORKING\\train_new.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acb70251",
      "metadata": {
        "id": "acb70251"
      },
      "outputs": [],
      "source": [
        "test_new=pd.read_csv(r'C:\\Users\\System162L\\Downloads\\QC_WORKING\\test_new.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c72cdd91",
      "metadata": {
        "id": "c72cdd91",
        "outputId": "63fc8dd3-f275-4d1a-c014-f54f222c8353"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1800 candidates, totalling 5400 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\System162L\\anaconda3\\Lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "C:\\Users\\System162L\\anaconda3\\Lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.65, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.65\n",
            "Best Y1 params: {'feature_fraction': 0.65, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 700, 'num_leaves': 60}\n",
            "Best Y1 R2 Validation: 0.7624392215224857\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['best_model_y1_with_OP.pkl']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split,GridSearchCV\n",
        "from sklearn.metrics import make_scorer,r2_score\n",
        "\n",
        "#prepare features (old and new)\n",
        "features_base=list(\"ABCDEFGHIJKLMN\") + ['time']\n",
        "new_features=['O','P']\n",
        "\n",
        "#combine features from original and new train data-sets\n",
        "X_y1=pd.concat([train[features_base],train_new[new_features]],axis=1)\n",
        "y_y1=train['Y1']\n",
        "\n",
        "\n",
        "X1_train,X1_val,y1_train,y1_val=train_test_split(\n",
        "    X_y1,y_y1,test_size=0.2,random_state=101,shuffle=True\n",
        ")\n",
        "\n",
        "#def parameter grid for Y1\n",
        "param_grid_y1={\n",
        "    'n_estimators': [500,700,900,1100,1300,1500],\n",
        "    'max_depth': [6,7,8,9,10],\n",
        "    'learning_rate': [0.008,0.01,0.02,0.03],\n",
        "    'num_leaves': [55,60,63,65,70],\n",
        "    'feature_fraction': [0.65,0.7,0.75]\n",
        "}\n",
        "\n",
        "#Base LGBM model for GridSearchCV\n",
        "model_y1_gs=lgb.LGBMRegressor(objective='regression',metric='rmse',boosting_type='gbdt',random_state=101)\n",
        "\n",
        "#custom scorer for R2\n",
        "r2_scorer_y1=make_scorer(r2_score)\n",
        "\n",
        "#for early stopping in GridSearchCV,I define fit params:\n",
        "fit_params_y1={\n",
        "    'eval_set': [(X1_val,y1_val)],\n",
        "    'eval_metric': 'rmse',\n",
        "    'early_stopping_rounds': 50,\n",
        "    'verbose': False\n",
        "}\n",
        "\n",
        "#grid Search for Y1\n",
        "grid_search_y1=GridSearchCV(\n",
        "    estimator=model_y1_gs,\n",
        "    param_grid=param_grid_y1,\n",
        "    scoring=r2_scorer_y1,\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    verbose=2,\n",
        "    refit=True\n",
        ")\n",
        "\n",
        "grid_search_y1.fit(X1_train,y1_train,**fit_params_y1)\n",
        "\n",
        "print(\"Best Y1 params:\",grid_search_y1.best_params_)\n",
        "print(\"Best Y1 R2 Validation:\",grid_search_y1.best_score_)\n",
        "\n",
        "#save best model for Y1\n",
        "import joblib\n",
        "joblib.dump(grid_search_y1.best_estimator_,'best_model_y1_with_OP.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f027873",
      "metadata": {
        "id": "4f027873",
        "outputId": "6c1a1aba-e0ef-42d2-8587-a2b11c21278b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'feature_fraction': 0.65,\n",
              " 'learning_rate': 0.01,\n",
              " 'max_depth': 10,\n",
              " 'n_estimators': 700,\n",
              " 'num_leaves': 60}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grid_search_y1.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1530e3b1",
      "metadata": {
        "scrolled": true,
        "id": "1530e3b1",
        "outputId": "3cfddb3f-08d0-4b96-d637-551fd918b02a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 2250 candidates, totalling 6750 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\System162L\\anaconda3\\Lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "C:\\Users\\System162L\\anaconda3\\Lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Y2 params: {'feature_fraction': 0.65, 'learning_rate': 0.03, 'max_depth': 8, 'n_estimators': 700, 'num_leaves': 32}\n",
            "Best Y2 R2 Validation: 0.7791742054216387\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['best_model_y2_with_OP.pkl']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#prepare features (old andd new)\n",
        "X_y2=pd.concat([train[features_base],train_new[new_features]],axis=1)\n",
        "y_y2=train['Y2']\n",
        "\n",
        "#split train,val\n",
        "X2_train,X2_val,y2_train,y2_val=train_test_split(\n",
        "    X_y2,y_y2,test_size=0.2,random_state=202,shuffle=True\n",
        ")\n",
        "\n",
        "param_grid_y2={\n",
        "    'n_estimators': [500,700,900,1100,1300,1500],\n",
        "    'max_depth': [6,7,8,9,10],\n",
        "    'learning_rate': [0.03,0.04,0.05,0.06,0.07],\n",
        "    'num_leaves': [25,28,30,32,35],\n",
        "    'feature_fraction': [0.65,0.7,0.75]\n",
        "}\n",
        "\n",
        "model_y2_gs=lgb.LGBMRegressor(objective='regression',metric='rmse',boosting_type='gbdt',random_state=202)\n",
        "\n",
        "r2_scorer_y2=make_scorer(r2_score)\n",
        "\n",
        "fit_params_y2={\n",
        "    'eval_set': [(X2_val,y2_val)],\n",
        "    'eval_metric': 'rmse',\n",
        "    'early_stopping_rounds': 50,\n",
        "    'verbose': False\n",
        "}\n",
        "\n",
        "grid_search_y2=GridSearchCV(\n",
        "    estimator=model_y2_gs,\n",
        "    param_grid=param_grid_y2,\n",
        "    scoring=r2_scorer_y2,\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    verbose=2,\n",
        "    refit=True\n",
        ")\n",
        "\n",
        "grid_search_y2.fit(X2_train,y2_train,**fit_params_y2)\n",
        "\n",
        "print(\"Best Y2 params:\",grid_search_y2.best_params_)\n",
        "print(\"Best Y2 R2 Validation:\",grid_search_y2.best_score_)\n",
        "\n",
        "joblib.dump(grid_search_y2.best_estimator_,'best_model_y2_with_OP.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3541e093",
      "metadata": {
        "id": "3541e093",
        "outputId": "1297da01-3d9c-4b0f-c779-dab849777931"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'feature_fraction': 0.65,\n",
              " 'learning_rate': 0.03,\n",
              " 'max_depth': 8,\n",
              " 'n_estimators': 700,\n",
              " 'num_leaves': 32}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grid_search_y2.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ff6b35e",
      "metadata": {
        "scrolled": true,
        "id": "6ff6b35e",
        "outputId": "065a8179-1fc3-4889-de62-c1b56fa38e73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final submission saved as submission_with_OP.csv\n"
          ]
        }
      ],
      "source": [
        "#combine features for full train set and test set\n",
        "X_all_final=pd.concat([train[features_base],train_new[new_features]],axis=1)\n",
        "y1_full=train['Y1']\n",
        "y2_full=train['Y2']\n",
        "X_test_final=pd.concat([test[features_base],test_new[new_features]],axis=1)\n",
        "\n",
        "#load best parameters from grid search best models\n",
        "best_params_final_y1=grid_search_y1.best_params_\n",
        "best_params_final_y2=grid_search_y2.best_params_\n",
        "\n",
        "#add fixed parameters\n",
        "fixed_params={\n",
        "    'objective': 'regression',\n",
        "    'metric': 'rmse',\n",
        "    'verbosity': -1,\n",
        "    'boosting_type': 'gbdt'\n",
        "}\n",
        "\n",
        "final_params_y1={**best_params_final_y1,**fixed_params,'random_state': 101}\n",
        "final_params_y2={**best_params_final_y2,**fixed_params,'random_state': 202}\n",
        "\n",
        "#training main\n",
        "final_model_y1=lgb.LGBMRegressor(**final_params_y1)\n",
        "final_model_y1.fit(X_all_final,y1_full)\n",
        "\n",
        "final_model_y2=lgb.LGBMRegressor(**final_params_y2)\n",
        "final_model_y2.fit(X_all_final,y2_full)\n",
        "\n",
        "#pred on test::\n",
        "y1_test_preds=final_model_y1.predict(X_test_final)\n",
        "y2_test_preds=final_model_y2.predict(X_test_final)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "submission_final_with_OP=pd.DataFrame({\n",
        "    'id': test['id'].astype(int),\n",
        "    'Y1': y1_test_preds.astype(float),\n",
        "    'Y2': y2_test_preds.astype(float)\n",
        "})\n",
        "\n",
        "submission_final_with_OP.to_csv('submission_OP_LGBM_KFOLD_GRIDSEARCH.csv',index=False)\n",
        "print(\"Final submission saved as submission_with_OP.csv\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}